{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09698cc-c050-4065-834e-54baa503764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c036a-2299-47e4-9930-ac1315b3f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd3529-1a4a-4cc4-8dea-70d22e7aa3b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220bfa4-38c3-4a12-9c38-67a050c0a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9fbd4a-4951-45cc-add2-dec8cf535015",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd1630-7519-4196-87f4-543146439428",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9126c-8b08-4503-af6a-bd7f311f8561",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2c9efc-8cd0-439a-8224-cf2a268c9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035cc23-c29a-4ec0-a725-40fbcf322087",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74ed94-52fc-4c0f-a557-71e848a09010",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18aea0-9a08-44e3-88fe-9491dbe5f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfde447-a934-4bc9-a874-526aad27d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, DataCollatorWithPadding, TrainingArguments, Trainer,pipeline\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from peft import PeftConfig, PeftModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9e165-280b-41a6-9d0c-a9bad3af45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import evaluate\n",
    "import datasets\n",
    "import collections\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from time import perf_counter\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    "    disable_progress_bar\n",
    ")\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    IntervalStrategy\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cache_dir = None\n",
    "\n",
    "%watermark -a 'Ethen' -d -u -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd9525-19f6-4b32-84d3-c19a66a72b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import transformers\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "\n",
    "from squad_dataset import SquadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd5ed7-da64-4ea5-ab87-efe2dd30652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667e2f3-860d-4e31-96f5-8936848891ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/data.csv')\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c5678-3ded-44f0-9e4f-7383088119c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_qtn=[\"data\"]\n",
    "qtndata = []\n",
    "qtndf=pd.DataFrame(qtndata, columns=column_names_qtn)\n",
    "for index, row in df.iterrows():\n",
    "  lst=[]\n",
    "  qas=[{\"question\": row['question'], \"id\":str(uuid.uuid4().hex), \"answers\":[{\"text\":row['answer'] ,\"answer_start\": int(row['answer_start'])}]}]\n",
    "  paragraphs=[{\"context\": row['context'], \"qas\": qas}]\n",
    "  lst.append({\"title\":'introduction', \"paragraphs\":paragraphs})\n",
    "qtndf.loc[len(qtndf.index)] = [lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62e0e1-16a2-42d6-9b1b-62bef82a0cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eeb8b8-b384-4fb4-aaaf-bc44ee62119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtndf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f85a1-1828-4e39-b029-63e6ee36cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = Dataset.from_pandas(qtndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d95dbd-4162-4ab4-b608-afe024a2bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = traindataset.remove_columns([\"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24ad94-45f1-4e6c-aa9b-9516a4e78f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42e04a-a417-4e1f-90f6-437ad8128801",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_from_hug = load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3d116-2279-46a1-a244-4ccaaf23e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_from_hug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39666e8-c184-4990-b184-a0a3ade2d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_from_hug['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5455964-4b57-4b5f-8324-cecc84742edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset.to_json(\"./data/train.json\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ce4f3-712e-424d-a378-763c636cc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f26deb-4b75-42b5-8f56-12a7ee8a0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfv = pd.read_csv('./data/validation.csv')\n",
    "\n",
    "dfv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d961290-1512-45fb-b935-5caf2e67b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49ced7-8c4f-48fc-88b2-79f17cad4648",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_qtnv=[\"data\"]\n",
    "qtndatav = []\n",
    "qtndfv=pd.DataFrame(qtndata, columns=column_names_qtn)\n",
    "for index, row in dfv.iterrows():\n",
    "  lst=[]\n",
    "  qas=[{\"question\": row['question'], \"id\":str(uuid.uuid4().hex), \"answers\":[{\"text\":row['answer'] ,\"answer_start\": int(row['answer_start'])}]}]\n",
    "  paragraphs=[{\"context\": row['context'], \"qas\": qas}]\n",
    "  lst.append({\"title\":'introduction', \"paragraphs\":paragraphs})\n",
    "qtndfv.loc[len(qtndfv.index)] = [lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50936cf9-0741-46d0-8f47-4039904bc409",
   "metadata": {},
   "outputs": [],
   "source": [
    "qtndfv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41abe0a-6127-4938-b334-23b77e758ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationdataset = Dataset.from_pandas(qtndfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4187868-91f0-45f9-ad0a-4ac7ad262c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationdataset = validationdataset.remove_columns([\"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6061fe-6364-4541-bdb1-263b12f0a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationdataset.to_json(\"./data/valid.json\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0262c-0c89-485d-9522-7dae177cfb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87155eb0-72be-414d-9c75-324d8f7a8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "validationdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04030a9d-0a26-48f5-8a43-941d3e2d5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformers.utils.logging.set_verbosity_error()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "LEARNING_RATE = 5e-5\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "VALID_DATA_PATH = \"./data/valid.json\"\n",
    "DATA_PATH = \"./data/train.json\"\n",
    "MODEL_PATH = \"bert-base-uncased\"\n",
    "MODEL_SAVE_PATH = f\"./bert-qa/models/{MODEL_PATH}-lr{LEARNING_RATE}-epochs{EPOCHS}-batchsize{BATCH_SIZE}-LORA-retrain/\"\n",
    "LORA = True\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "model = BertForQuestionAnswering.from_pretrained(MODEL_PATH).to(device)\n",
    "\n",
    "if LORA:\n",
    "    config = LoraConfig(\n",
    "        task_type = \"QUESTION_ANS\",\n",
    "        inference_mode = False,\n",
    "        r = 16,\n",
    "        lora_alpha = 32,\n",
    "        lora_dropout = 0.05,\n",
    "        fan_in_fan_out = False,\n",
    "        bias = \"none\",\n",
    "    )\n",
    "\n",
    "    print(\"# Trainable Parameters Before LoRA\")\n",
    "    print(model.num_parameters())\n",
    "    model = get_peft_model(model, config)\n",
    "    print(\"# Trainable Parameters After LoRA\") \n",
    "    model.print_trainable_parameters()\n",
    "\n",
    "tdataset = SquadDataset(DATA_PATH, tokenizer)\n",
    "vdataset = SquadDataset(VALID_DATA_PATH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64a3cd-8ffc-4891-b1a9-17d6c57d9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset=tdataset\n",
    "val_dataset=vdataset\n",
    "test_dataset=vdataset\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fc9c1-3dec-4fcb-b30b-28f12e9e33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store loss and accuracy for plotting\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e34b4-f08b-4f7e-90e8-16d3c29a344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "start = timeit.default_timer() \n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    for idx, sample in enumerate(tqdm(train_dataloader)):\n",
    "        input_ids = sample['input_ids'].to(device)\n",
    "        attention_mask = sample['attention_mask'].to(device)\n",
    "        start_positions = sample['start_positions'].to(device)\n",
    "        end_positions = sample['end_positions'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Calculate accuracy\n",
    "        start_preds = outputs.start_logits.argmax(dim=1)\n",
    "        end_preds = outputs.end_logits.argmax(dim=1)\n",
    "        correct_predictions += ((start_preds == start_positions) & (end_preds == end_positions)).sum().item()\n",
    "        total_samples += len(start_positions)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_running_loss += loss.item()\n",
    "\n",
    "    train_loss = train_running_loss / (idx + 1)\n",
    "    epoch_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    val_total_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, sample in enumerate(tqdm(val_dataloader)):\n",
    "            input_ids = sample['input_ids'].to(device)\n",
    "            attention_mask = sample['attention_mask'].to(device)\n",
    "            start_positions = sample['start_positions'].to(device)\n",
    "            end_positions = sample['end_positions'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss = outputs[0]\n",
    "            val_total_loss += val_loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            val_start_preds = outputs.start_logits.argmax(dim=1)\n",
    "            val_end_preds = outputs.end_logits.argmax(dim=1)\n",
    "            val_correct_predictions += ((val_start_preds == start_positions) & (val_end_preds == end_positions)).sum().item()\n",
    "            val_total_samples += len(start_positions)\n",
    "            \n",
    "            val_running_loss += outputs.loss.item()\n",
    "        val_loss = val_running_loss / (idx + 1)\n",
    "    epoch_val_loss = val_total_loss / len(val_dataloader)\n",
    "    val_accuracy = val_correct_predictions / val_total_samples\n",
    "\n",
    "    print(\"-\"*30)\n",
    "    print(f\"Train Loss EPOCH {epoch+1}: {train_loss:.4f}\")\n",
    "    print(f\"Valid Loss EPOCH {epoch+1}: {val_loss:.4f}\")\n",
    "    print(\"-\"*30)\n",
    "    print(f'Epoch {epoch + 1}/{3}:')\n",
    "    print(f'  Training Loss: {epoch_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'  Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "stop = timeit.default_timer()\n",
    "print(f\"Training Time: {stop-start:.2f}s\")\n",
    "\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "true = []\n",
    "with torch.no_grad():\n",
    "    for idx, sample in enumerate(tqdm(test_dataloader)):\n",
    "        input_ids = sample['input_ids'].to(device)\n",
    "        attention_mask = sample['attention_mask'].to(device)\n",
    "        start_positions = sample['start_positions']\n",
    "        end_positions = sample['end_positions']\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1).cpu().detach()\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1).cpu().detach()\n",
    "\n",
    "        preds.extend([[int(i), int(j)] for i, j in zip(start_pred, end_pred)])\n",
    "        true.extend([[int(i), int(j)] for i, j in zip(start_positions, end_positions)])\n",
    "\n",
    "preds = [item for sublist in preds for item in sublist]\n",
    "true = [item for sublist in true for item in sublist]\n",
    "\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "# f1_value = f1_score(true, preds, average=\"macro\")\n",
    "# print(f\"F1 Score: {f1_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35801042-8d77-49e2-9b6c-4c3345b84ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lora_infer(question, context, MODEL_PATH):\n",
    "    config = PeftConfig.from_pretrained(MODEL_PATH)\n",
    "    model = PeftModel.from_pretrained(BertForQuestionAnswering.from_pretrained(config.base_model_name_or_path), MODEL_PATH)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "    start = timeit.default_timer()\n",
    "    qa_model = pipeline(task=\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "    stop = timeit.default_timer()\n",
    "    print(f\"Inference Time: {stop-start:.2f}s\")\n",
    "    return(qa_model(question=question, context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6adcf-e7f6-4034-b544-a487a83a3ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_infer(question, context, MODEL_PATH):\n",
    "    model = BertForQuestionAnswering.from_pretrained(MODEL_PATH)\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "    start = timeit.default_timer()\n",
    "    qa_model = pipeline(task=\"question-answering\", model=model, tokenizer=tokenizer)\n",
    "    stop = timeit.default_timer()\n",
    "    print(f\"Inference Time: {stop-start:.2f}s\")\n",
    "    return(qa_model(question=question, context=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5d22c-d655-4582-a1e7-69cd69f9857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./models/qa-bert-base\"\n",
    "LORA = False\n",
    "\n",
    "question = \"who is vendor?\"\n",
    "context = \"this statement of work (sow) is entered into as of november 30th, 2022 (the sow effective date), by and between unified com (customer), a corporation located at salesforce tower, 415 mission street, 3rd floar, seattle, ca 84105, and transunion information services, inc. (vendor), a middleeast corporation with offices at 1906 reston metrplaza, suite 500 reston, wa 201390. this sow is subject that certain master. service agreement entered in by and between the vendor and customer with an effective date of 11/30/2022,as amended (the master service agreement, or the msa, or the agreement.  \"\n",
    "if LORA:\n",
    "    print(lora_infer(question, context, MODEL_PATH))\n",
    "else:\n",
    "    print(vanilla_infer(question, context, MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f21c1a1-a057-4b48-b27e-d135e3fe11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./models/qa-bert-base\"\n",
    "LORA = True\n",
    "\n",
    "question = \"who is customer?\"\n",
    "context = \"this statement of work (sow) is entered into as of november 30th, 2022 (the sow effective date), by and between unified com (customer), a corporation located at salesforce tower, 415 mission street, 3rd floar, seattle, ca 84105, and transunion information services, inc. (vendor), a middleeast corporation with offices at 1906 reston metrplaza, suite 500 reston, wa 201390. this sow is subject that certain master. service agreement entered in by and between the vendor and customer with an effective date of 11/30/2022,as amended (the master service agreement, or the msa, or the agreement.  \"\n",
    "\n",
    "if LORA:\n",
    "    print(lora_infer(question, context, MODEL_PATH))\n",
    "else:\n",
    "    print(vanilla_infer(question, context, MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72881a8a-c2b3-4a4b-a6e6-391c606f2d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d441b1e-685c-4cdb-8b21-910c3f3ff5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962672c-9a6e-42de-a702-e49660799524",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=dataset['train'].select(range(5000))\n",
    "val_dataset=dataset['validation'].select(range(500))\n",
    "test_dataset=dataset['validation'].select(range(500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc4843-2916-42eb-80d1-a5ada7a53038",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in train_dataset.select(range(2)):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1bbf1-e4bb-4e3f-af69-2c7371b467d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b05d25-0ea6-483a-88b3-d3a02c8ff3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "start = timeit.default_timer() \n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    for idx, sample in enumerate(tqdm(train_dataloader)):\n",
    "        input_ids = sample['input_ids'].to(device)\n",
    "        attention_mask = sample['attention_mask'].to(device)\n",
    "        start_positions = sample['start_positions'].to(device)\n",
    "        end_positions = sample['end_positions'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Calculate accuracy\n",
    "        start_preds = outputs.start_logits.argmax(dim=1)\n",
    "        end_preds = outputs.end_logits.argmax(dim=1)\n",
    "        correct_predictions += ((start_preds == start_positions) & (end_preds == end_positions)).sum().item()\n",
    "        total_samples += len(start_positions)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_running_loss += loss.item()\n",
    "\n",
    "    train_loss = train_running_loss / (idx + 1)\n",
    "    epoch_train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    val_total_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, sample in enumerate(tqdm(val_dataloader)):\n",
    "            input_ids = sample['input_ids'].to(device)\n",
    "            attention_mask = sample['attention_mask'].to(device)\n",
    "            start_positions = sample['start_positions'].to(device)\n",
    "            end_positions = sample['end_positions'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss = outputs[0]\n",
    "            val_total_loss += val_loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            val_start_preds = outputs.start_logits.argmax(dim=1)\n",
    "            val_end_preds = outputs.end_logits.argmax(dim=1)\n",
    "            val_correct_predictions += ((val_start_preds == start_positions) & (val_end_preds == end_positions)).sum().item()\n",
    "            val_total_samples += len(start_positions)\n",
    "            \n",
    "            val_running_loss += outputs.loss.item()\n",
    "        val_loss = val_running_loss / (idx + 1)\n",
    "    epoch_val_loss = val_total_loss / len(val_dataloader)\n",
    "    val_accuracy = val_correct_predictions / val_total_samples\n",
    "\n",
    "    print(\"-\"*30)\n",
    "    print(f\"Train Loss EPOCH {epoch+1}: {train_loss:.4f}\")\n",
    "    print(f\"Valid Loss EPOCH {epoch+1}: {val_loss:.4f}\")\n",
    "    print(\"-\"*30)\n",
    "    print(f'Epoch {epoch + 1}/{3}:')\n",
    "    print(f'  Training Loss: {epoch_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'  Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "stop = timeit.default_timer()\n",
    "print(f\"Training Time: {stop-start:.2f}s\")\n",
    "\n",
    "model.save_pretrained(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.eval()\n",
    "preds = []\n",
    "true = []\n",
    "with torch.no_grad():\n",
    "    for idx, sample in enumerate(tqdm(test_dataloader)):\n",
    "        input_ids = sample['input_ids'].to(device)\n",
    "        attention_mask = sample['attention_mask'].to(device)\n",
    "        start_positions = sample['start_positions']\n",
    "        end_positions = sample['end_positions']\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        start_pred = torch.argmax(outputs['start_logits'], dim=1).cpu().detach()\n",
    "        end_pred = torch.argmax(outputs['end_logits'], dim=1).cpu().detach()\n",
    "\n",
    "        preds.extend([[int(i), int(j)] for i, j in zip(start_pred, end_pred)])\n",
    "        true.extend([[int(i), int(j)] for i, j in zip(start_positions, end_positions)])\n",
    "\n",
    "preds = [item for sublist in preds for item in sublist]\n",
    "true = [item for sublist in true for item in sublist]\n",
    "\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "# f1_value = f1_score(true, preds, average=\"macro\")\n",
    "# print(f\"F1 Score: {f1_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95269b10-a975-4508-8602-21f68a10a29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "config = PeftConfig.from_pretrained(MODEL_PATH)\n",
    "model = PeftModel.from_pretrained(BertForQuestionAnswering.from_pretrained(config.base_model_name_or_path), MODEL_PATH)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(config.base_model_name_or_path)\n",
    "question = \"\"\n",
    "context = \"\"\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "#     'distilbert-base-uncased-distilled-squad')\n",
    "# model = DistilBertForQuestionAnswering.from_pretrained(\n",
    "#     'distilbert-base-uncased-distilled-squad')\n",
    "input_ids = torch.tensor(tokenizer.encode(\n",
    "    question,context, max_length=256, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "start_positions = torch.tensor([1])\n",
    "end_positions = torch.tensor([3])\n",
    "\n",
    "outputs = model(input_ids, start_positions=start_positions,\n",
    "                end_positions=end_positions)\n",
    "loss, start_scores, end_scores = outputs[:3]\n",
    "\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "answer = tokenizer.convert_tokens_to_string(\n",
    "    all_tokens[torch.argmax(start_scores): torch.argmax(end_scores) + 1])\n",
    "print('*************')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d248cd-4ee2-4d42-b8c5-874c0cab210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "question_answererold = pipeline(\"question-answering\", model='distilbert-base-cased-distilled-squad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c073d8b-52d6-44b7-95a1-b88323873197",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\n",
    "context = \"\"\n",
    "result = question_answererold(question=question, context=context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039e24b-c9c5-4b60-8214-eab7e52cbfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e1c084-475e-4f91-af37-193f097d621d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba94cca-0ec3-493a-8abf-94ce8588f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "# Example domain-specific data\n",
    "domain_data = [\n",
    "    \"The company plans to launch a new product next month.\",\n",
    "    \"Our team successfully completed the project ahead of schedule.\",\n",
    "    \"Customers are excited about the upcoming sale.\"\n",
    "]\n",
    " \n",
    "# Function to generate variations while maintaining POS tags\n",
    "def generate_synthetic_data(sentences):\n",
    "    synthetic_data = []\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "        pos_tags = nltk.pos_tag(words)  # Tag the domain-specific sentence\n",
    "        \n",
    "        # Generate variations while preserving POS tags (e.g., word substitutions, word order changes)\n",
    "        # Modify the sentence here while ensuring POS tag coherence\n",
    "        \n",
    "        # Append modified sentence with its POS tags to synthetic data\n",
    "        synthetic_data.append(pos_tags)\n",
    "    \n",
    "    return synthetic_data\n",
    " \n",
    "# Generating synthetic data based on domain-specific data\n",
    "synthetic_data = generate_synthetic_data(domain_data)\n",
    " \n",
    "# Display the synthetic data with POS tags\n",
    "for tagged_sentence in synthetic_data:\n",
    "    print(tagged_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee468d-9290-4f49-8365-09946c11657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0cd776-86c7-4c4c-9c45-4aaf67ead17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3adea7-d520-4382-ada7-c49ac1262956",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0827c4-66b9-44ce-bed6-64c259981fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import(\n",
    "  AutoModelForQuestionAnswering,\n",
    "  AutoTokenizer,\n",
    "  pipeline\n",
    ")\n",
    "model_name = \"sjrhuschlee/flan-t5-large-squad2\"\n",
    "\n",
    "# a) Using pipelines\n",
    "nlp = pipeline(\n",
    "  'question-answering',\n",
    "  model=model_name,\n",
    "  tokenizer=model_name,\n",
    "  # trust_remote_code=True, # Do not use if version transformers>=4.31.0\n",
    ")\n",
    "qa_input = {\n",
    "'question': f'{nlp.tokenizer.cls_token}who is customer?',  # '<cls>Where do I live?'\n",
    "'context': 'this statement of work (sow) is entered into as of october 11th, 2021 (the sow effective date), by and between abc com (customer), a corporation located at abc tower, 514 st global street, 1rd floor, seattle, ca 78192, and transunion information services, inc. (vendor), a middleeast corporation with offices at 1906 reston metrplaza, suite 500 reston, wa 18903. this sow is subject that certain master. service agreement entered in by and between the vendor and customer with an effective date of 10/11/2021,as amended (the master service agreement, or the msa, or the agreement.'\n",
    "}\n",
    "res = nlp(qa_input)\n",
    "# {'score': 0.984, 'start': 30, 'end': 37, 'answer': ' London'}\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "  model_name,\n",
    "  # trust_remote_code=True # Do not use if version transformers>=4.31.0\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "question = f'{tokenizer.cls_token}what is effective date?'  # '<cls>Where do I live?'\n",
    "context = 'this statement of work (sow) is entered into as of december 30th, 2022 (the sow effective date), by and between salesforce com (customer), a corporation located at salesforce tower, 415 mission street, 3rd floar,san francisco, ca 84105, and neustar information services, inc. (vendor), a delaware corporation with offices at 1906 reston metrplaza, suite 500 reston, wa 201390. this sowy is subject tthat certain master. service agreement entered in by and between the vendor and customer with an effective date of 06/30/2016,as amended (the master service agreement, or the msa, or the agreement.'\n",
    "encoding = tokenizer(question, context, return_tensors=\"pt\")\n",
    "output = model(\n",
    "  encoding[\"input_ids\"],\n",
    "  attention_mask=encoding[\"attention_mask\"]\n",
    ")\n",
    "\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"][0].tolist())\n",
    "answer_tokens = all_tokens[torch.argmax(output[\"start_logits\"]):torch.argmax(output[\"end_logits\"]) + 1]\n",
    "answer = tokenizer.decode(tokenizer.convert_tokens_to_ids(answer_tokens))\n",
    "# 'London'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70736c1-2131-4305-8215-985ba046052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e589944e-7343-4748-ab4b-c3b5d6331c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64820c99-8cce-4de2-add9-50861cf8280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3411ca0-afbb-4186-a2ca-d65346942ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54a60d-4abf-4805-bc76-9351d3641169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

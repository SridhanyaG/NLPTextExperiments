{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5251d-fe41-43ba-9fa0-317a42ecab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3ce19-4665-4579-b956-c140e7f0b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, DataCollatorWithPadding, TrainingArguments, Trainer,pipeline\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72da33e-7cf6-49ae-ae8e-5bde27bb5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. magic for inline plot\n",
    "# 2. magic to print version\n",
    "# 3. magic so that the notebook will reload external python modules\n",
    "# 4. magic to enable retina (high resolution) plots\n",
    "# https://gist.github.com/minrk/3301035\n",
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import evaluate\n",
    "import datasets\n",
    "import collections\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from time import perf_counter\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    "    disable_progress_bar\n",
    ")\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    IntervalStrategy\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cache_dir = None\n",
    "\n",
    "%watermark -a 'Ethen' -d -u -iv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9abe332-cd22-4a3f-a166-fa618b7f1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_qtn=[\"id\", \"title\", \"context\", \"question\", \"answers\"]\n",
    "qtndata = []\n",
    "qtndf=pd.DataFrame(qtndata, columns=column_names_qtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417b56f-e362-4d72-a077-b9acd6164990",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst={}\n",
    "lst2={}\n",
    "lst[\"what is coffee made of?\"]={\"text\":[\"roasted coffee beans\"], \"answer_start\":[int(36)]}\n",
    "lst[\"what is coffee ingredient?\"]={\"text\":[\"roasted coffee beans\"], \"answer_start\":[int(36)]}\n",
    "lst[\"what are the coffee flavors available?\"]={\"text\":[\"espresso, french press, caffe latte, or already-brewed canned coffee\"], \"answer_start\":[int(644)]}\n",
    "lst2[\"what are the coffee types?\"]={\"text\":[\"C. arabica and C . robusta. \"], \"answer_start\":[int(51)]}\n",
    "lst2[\"what are the coffee varieties?\"]={\"text\":[\"C. arabica and C . robusta. \"], \"answer_start\":[int(51)]}\n",
    "lst2[\"which countries cultivate coffee?\"]={\"text\":[\"70 countries\"], \"answer_start\":[int(116)]}\n",
    "context1=\"coffee is a beverage prepared from roasted coffee beans (ingredient). darkly colored, bitter, (appearance) and slightly acidic, coffee has a stimulating effect on humans, primarily due to its caffeine content. it has the highest sales in the world market for hot drinks. the seeds of the coffea plant fruits are separated to produce unroasted green coffee beans. the beans are roasted and then ground into fine particles typically steeped in hot water before being filtered out, producing a cup of coffee. it is usually served hot, although chilled or iced coffee is common. coffee can be prepared and presented in a variety of ways for e.g., espresso, french press, caffe latte, or already-brewed canned coffee (flavors). sugar, sugar substitutes, milk, and cream are often added to mask the bitter taste or enhance the flavor .\"\n",
    "context2=\"The two most commonly grown coffee bean types are C. arabica and C . robusta. Coffee plants are cultivated in over 70 countries, primarily in the equatorial regions of the Americas, Southeast Asia, the Indian subcontinent, and Africa. As of 2018, Brazil was the leading grower of coffee beans, producing 35% of the world's total. Green, unroasted coffee is traded as an agricultural commodity. Despite sales of coffee reaching billions of dollars worldwide, farmers producing coffee beans disproportionately live in poverty. Critics of the coffee industry have also pointed to its negative impact on the environment and the clearing of land for coffee-growing and water use.\"\n",
    "\n",
    "for key, value in lst.items():\n",
    "    print(value)\n",
    "    qtndf.loc[len(qtndf.index)] = [str(uuid.uuid4().hex), 'introduction', context, key, value]\n",
    "for key, value in lst2.items():\n",
    "    print(value)\n",
    "    qtndf.loc[len(qtndf.index)] = [str(uuid.uuid4().hex), 'countries', context2, key, value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e27e8-782a-4f85-bbb7-997239eb4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312af650-741f-4159-98ec-973b31af9c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "qatrain=dataset['train'].select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2fa67-e997-4dd4-9a37-e45bbb944d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qatest=dataset['validation'].select(range(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9bdf5-ec37-4994-82d5-66ae8e508e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = qatrain.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f0ac6-b0d6-43ae-bd08-e0df6b8d04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa33ab-e0d2-40fc-ac37-5cc5c77564a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df = pd.concat([df_pandas, qtndf])\n",
    "traindataset = Dataset.from_pandas(overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741bae3-335f-47e5-a8aa-19b0419c47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e05c75-1106-497e-83f3-bc06240650ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54206af4-f02b-4709-b2ef-6fdbc3e5e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56704e52-3577-408b-b696-675617c9a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = traindataset.remove_columns([\"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4d9fd0-736a-4bd7-85bd-10da47cf82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2056be-5563-4610-a427-16e0c564b1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ffd7df-0946-457c-bbd0-a288536d818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train']=traindataset\n",
    "dataset['validation']=qatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5681396a-1843-40af-b780-c3da623a3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5be1b-8e10-4415-bc2d-2ec454e77662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment with different public model checkpoints\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "task_name = \"squad-try-three\" # \"squad_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277b675-52b5-4870-8a98-09c8350055bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, cache_dir=cache_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a18599-cf67-4d37-9deb-865e8a66b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum length of a feature (question and context)\n",
    "max_length = 384\n",
    "# overlap between two part of the context\n",
    "doc_stride = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd2b5f9-b4f2-44d4-b568-fc294b2de183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_qa_train(examples):\n",
    "    \"\"\"Prepare training data, input features plus label for question answering dataset.\"\"\"\n",
    "    answers = examples[\"answers\"]\n",
    "    examples[\"question\"] = [question.strip() for question in examples[\"question\"]]\n",
    "    \n",
    "    # Tokenize our examples with truncation and padding, but keep overflows using a stride.\n",
    "    # This results in one example potentially generating several features when a context is\n",
    "    # long, each of those features having a context that overlaps a bit the previous\n",
    "    # feature's context to prevent chopping off answer span.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        stride=doc_stride,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    sample_mapping = tokenized_examples[\"overflow_to_sample_mapping\"]\n",
    "    offset_mapping = tokenized_examples[\"offset_mapping\"]\n",
    "\n",
    "     # We will label impossible answers with CLS token's index.\n",
    "    cls_index = 0\n",
    "\n",
    "    # start_positions and end_positions will be the labels for extractive question answering\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "\n",
    "        sample_index = sample_mapping[i]\n",
    "        answer = answers[sample_index]\n",
    "        \n",
    "        # if no answers are given, set CLS index as answer\n",
    "        if len(answer[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            start_char = answer[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answer[\"text\"][0])\n",
    "\n",
    "            sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "            # find the context's corresponding start and end token index\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "\n",
    "            # if answer is within the context offset, move the token_start_index and token_end_index\n",
    "            # to two ends of the answer else label it with cls index\n",
    "            offset_start_char = offset[token_start_index][0]\n",
    "            offset_end_char = offset[token_end_index][1]\n",
    "            if offset_start_char <= start_char and offset_end_char >= end_char:\n",
    "                while token_start_index < len(offset) and offset[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                start_position = token_start_index - 1\n",
    "\n",
    "                while offset[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                end_position = token_end_index + 1\n",
    "\n",
    "                tokenized_examples[\"start_positions\"].append(start_position)\n",
    "                tokenized_examples[\"end_positions\"].append(end_position)\n",
    "            else:\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00f453-2e33-46c2-9fb0-35e41473e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = dataset[\"train\"]\n",
    "answers = examples[\"answers\"]\n",
    "\n",
    "tokenized_examples = prepare_qa_train(examples)\n",
    "\n",
    "start_positions = tokenized_examples[\"start_positions\"]\n",
    "end_positions = tokenized_examples[\"end_positions\"]\n",
    "for i, input_ids in enumerate(tokenized_examples[\"input_ids\"]):\n",
    "    start = start_positions[i]\n",
    "    end = end_positions[i] + 1\n",
    "    string = tokenizer.decode(input_ids[start:end])\n",
    "    print(\"expected answer:\", answers[i][\"text\"][0])\n",
    "    print(\"preprocessing answer:\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac371c4-a1a9-4a9c-ad28-88b49a100773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevents progress bar from flooding our document\n",
    "disable_progress_bar()\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    prepare_qa_train,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    num_proc=8\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3913cb-8406-42c6-a218-b6368338a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_qa_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46d818-abff-47ff-bd0e-cc8884c2141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "fine_tuned_model_checkpoint = f\"{model_name}-fine_tuned-{task_name}\"\n",
    "\n",
    "if os.path.isdir(fine_tuned_model_checkpoint):\n",
    "    do_train = False\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(fine_tuned_model_checkpoint, cache_dir=cache_dir)\n",
    "else:\n",
    "    do_train = True\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint, cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e998238-aaf2-4b47-a311-c57beaedaf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DISABLE_MLFLOW_INTEGRATION'] = 'TRUE'\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=fine_tuned_model_checkpoint,\n",
    "    learning_rate=0.0001,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    # we set it to evaluate/save per epoch to avoid flowing console\n",
    "    evaluation_strategy=IntervalStrategy.EPOCH,\n",
    "    save_strategy=IntervalStrategy.EPOCH,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    do_train=do_train\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a265eae-63be-4833-b00a-dfc0fdcda9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainer.args.do_train:\n",
    "    train_output = trainer.train()\n",
    "    # saving the model which allows us to leverage\n",
    "    # .from_pretrained(model_path)\n",
    "    trainer.save_model(fine_tuned_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b438d-2016-4fea-b1a5-9c67fbaa9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29578e-8cf3-4afd-b311-0ae2c93ffcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=fine_tuned_model_checkpoint,\n",
    "    tokenizer=fine_tuned_model_checkpoint\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bcc743-6393-485e-85d7-990bd512f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = qa_pipeline({\n",
    "    \"question\": \"what is coffee made of?\",\n",
    "    \"context\": context1\n",
    "})\n",
    "# answer_text = example[\"answers\"][\"text\"][0]\n",
    "# print(\"output answer matches expected answer: \", output[\"answer\"] == answer_text) \n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138b3e9-4dcd-4366-a6d4-9399c292dfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = qa_pipeline({\n",
    "    \"question\": \"what are the coffee types?\",\n",
    "    \"context\": context2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d846d1e-b2e3-418c-b298-e99f664a08ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec1ef4-d46c-4cee-9e54-23abcc7cf965",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=bert_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e52ea-535f-448c-b468-ad63bfaf4d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a120f4-4ba1-4c5c-b86d-9305d66a8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./tqanew/results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    logging_dir='./tqanew/logs',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "#     report_to=\"wandb\",  # enable logging to W&B\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=qa_bert,\n",
    "    args=training_args,\n",
    "    train_dataset=qa_dataset['train'],\n",
    "    eval_dataset=qa_dataset['validation'],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Get initial metrics\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd030e7-9838-4ea9-9079-e407351351c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f16de-eb31-4392-bb67-053534ca2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad9ec4-dbb6-407b-8fd5-384255e9ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://ethen8181.github.io/machine-learning/deep_learning/question_answer/question_answer.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33497d74-7edf-4bba-8927-bf4b27e4311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9e248-f788-40a3-82ac-62d233d6faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, DataCollatorWithPadding, TrainingArguments, Trainer,pipeline\n",
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce6df8-a53a-4bb1-af02-ace16bd09e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_qtn=[\"id\", \"title\", \"context\", \"question\", \"answers\"]\n",
    "qtndata = []\n",
    "qtndf=pd.DataFrame(qtndata, columns=column_names_qtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa0286-818b-4db9-82d6-4cec92794a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst={}\n",
    "lst2={}\n",
    "lst[\"what is coffee made of?\"]={\"text\":[\"roasted coffee beans\"], \"answer_start\":[int(36)]}\n",
    "lst[\"what is coffee ingredient?\"]={\"text\":[\"roasted coffee beans\"], \"answer_start\":[int(36)]}\n",
    "lst[\"what are the coffee flavors available?\"]={\"text\":[\"espresso, french press, caffe latte, or already-brewed canned coffee\"], \"answer_start\":[int(644)]}\n",
    "lst2[\"what are the coffee types?\"]={\"text\":[\"C. arabica and C . robusta. \"], \"answer_start\":[int(51)]}\n",
    "lst2[\"what are the coffee varieties?\"]={\"text\":[\"C. arabica and C . robusta. \"], \"answer_start\":[int(51)]}\n",
    "lst2[\"which countries cultivate coffee?\"]={\"text\":[\"70 countries\"], \"answer_start\":[int(116)]}\n",
    "context1=\"coffee is a beverage prepared from roasted coffee beans (ingredient). darkly colored, bitter, (appearance) and slightly acidic, coffee has a stimulating effect on humans, primarily due to its caffeine content. it has the highest sales in the world market for hot drinks. the seeds of the coffea plant fruits are separated to produce unroasted green coffee beans. the beans are roasted and then ground into fine particles typically steeped in hot water before being filtered out, producing a cup of coffee. it is usually served hot, although chilled or iced coffee is common. coffee can be prepared and presented in a variety of ways for e.g., espresso, french press, caffe latte, or already-brewed canned coffee (flavors). sugar, sugar substitutes, milk, and cream are often added to mask the bitter taste or enhance the flavor .\"\n",
    "context2=\"The two most commonly grown coffee bean types are C. arabica and C . robusta. Coffee plants are cultivated in over 70 countries, primarily in the equatorial regions of the Americas, Southeast Asia, the Indian subcontinent, and Africa. As of 2018, Brazil was the leading grower of coffee beans, producing 35% of the world's total. Green, unroasted coffee is traded as an agricultural commodity. Despite sales of coffee reaching billions of dollars worldwide, farmers producing coffee beans disproportionately live in poverty. Critics of the coffee industry have also pointed to its negative impact on the environment and the clearing of land for coffee-growing and water use.\"\n",
    "\n",
    "for key, value in lst.items():\n",
    "    print(value)\n",
    "    qtndf.loc[len(qtndf.index)] = [str(uuid.uuid4().hex), 'introduction', context, key, value]\n",
    "for key, value in lst2.items():\n",
    "    print(value)\n",
    "    qtndf.loc[len(qtndf.index)] = [str(uuid.uuid4().hex), 'countries', context2, key, value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae801949-58ae-49a7-9dff-9a018da6c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = Dataset.from_pandas(pd.DataFrame(data=qtndf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd941259-da4e-4b3e-9501-719deca618ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.remove_columns([\"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686df4b1-2826-420a-9318-940942350197",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db80b90c-3ff6-45c3-9231-a9fd4090a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af84a3-97a3-4cd9-a288-444334ddacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset2 = concatenate_datasets([dataset['train'], temp])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b5248-6d58-4dbd-9f93-0376bda355d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bert_tokenizer = DistilBertTokenizer.from_pretrained(\n",
    "    'distilbert-base-uncased-distilled-squad')\n",
    "qa_bert = DistilBertForQuestionAnswering.from_pretrained(\n",
    "    'distilbert-base-uncased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c0b34-f8bd-494a-8661-6a7cd5415f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d56f49-5788-4a11-b788-d6d7baa6c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "questions = []\n",
    "answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f91d8-0478-4b57-b2bb-24cf820f7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcontexts = []\n",
    "vquestions = []\n",
    "vanswers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740f4c8-8407-4bb7-8de3-3bd9fdf2ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in dataset['train']:\n",
    "    contexts.append(row['context'])\n",
    "    questions.append(row['question'])\n",
    "    answers.append(row['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25912e2f-d8d9-4b9f-9887-f9256e84ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4c2cc-ec87-4514-b079-5c057b22a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in temp:\n",
    "    contexts.append(row['context'])\n",
    "    questions.append(row['question'])\n",
    "    answers.append(row['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b144261-94f3-409a-9dfe-4be06a623ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87348103-bbf8-43a3-956e-6031b538cae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in dataset['validation']:\n",
    "    vcontexts.append(row['context'])\n",
    "    vquestions.append(row['question'])\n",
    "    vanswers.append(row['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94e7b87-b77c-4fd5-ab2d-7b6d998d442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vcontexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a8cbb-b56e-449a-9365-985e5078e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(contexts, questions, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(vcontexts, vquestions, truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a5cc8-355b-4b09-97f5-fbc427bbb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_positions(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i in range(len(answers)):\n",
    "        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start'][0]))\n",
    "        end_char = answers[i]['answer_start'][0] + len(answers[i][\"text\"][0])\n",
    "        end_positions.append(end_char)\n",
    "        # end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'][0] - 1))\n",
    "        # if None, the answer passage has been truncated\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length\n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length\n",
    "    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
    "\n",
    "add_token_positions(train_encodings, answers)\n",
    "add_token_positions(val_encodings, vanswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d3160-20c9-426e-9c01-48a9346f4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = SquadDataset(train_encodings)\n",
    "val_dataset = SquadDataset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219b6e7-69c7-4dcb-b108-4c9f2a13f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=qa_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3324e26-5a27-4577-b87d-aa7b5dac645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "\n",
    "\n",
    "# Lists to store loss and accuracy for plotting\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_positions = batch['start_positions'].to(device)\n",
    "        end_positions = batch['end_positions'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    \n",
    "        # Calculate accuracy\n",
    "        start_preds = outputs.start_logits.argmax(dim=1)\n",
    "        end_preds = outputs.end_logits.argmax(dim=1)\n",
    "        correct_predictions += ((start_preds == start_positions) & (end_preds == end_positions)).sum().item()\n",
    "        total_samples += len(start_positions)\n",
    "    \n",
    "    \n",
    "    \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate accuracy and loss for the training set\n",
    "    epoch_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_total_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_batch in tqdm(val_loader):\n",
    "            input_ids = val_batch['input_ids'].to(device)\n",
    "            attention_mask = val_batch['attention_mask'].to(device)\n",
    "            start_positions = val_batch['start_positions'].to(device)\n",
    "            end_positions = val_batch['end_positions'].to(device)\n",
    "            val_outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "            val_loss = val_outputs[0]\n",
    "            val_total_loss += val_loss.item()\n",
    "    \n",
    "    \n",
    "    \n",
    "            # Calculate accuracy\n",
    "            val_start_preds = val_outputs.start_logits.argmax(dim=1)\n",
    "            val_end_preds = val_outputs.end_logits.argmax(dim=1)\n",
    "            val_correct_predictions += ((val_start_preds == start_positions) & (val_end_preds == end_positions)).sum().item()\n",
    "            val_total_samples += len(start_positions)\n",
    "\n",
    "\n",
    "    epoch_val_loss = val_total_loss / len(val_loader)\n",
    "    val_accuracy = val_correct_predictions / val_total_samples\n",
    "\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{3}:')\n",
    "    print(f'  Training Loss: {epoch_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'  Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea759df3-a34a-4fc8-83d5-7a5e188b642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_savenew/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a6275-cc5c-4c5e-8d0e-87b7285608f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune",
   "language": "python",
   "name": "finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
